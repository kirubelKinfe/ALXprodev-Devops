#!/bin/bash

# Script to fetch Pokémon data in parallel using background processes with robust error handling

# Define variables
POKEMON_LIST=("bulbasaur" "ivysaur" "venusaur" "charmander" "charmeleon")
OUTPUT_DIR="pokemon_data"
ERROR_FILE="errors.txt"
API_BASE_URL="https://pokeapi.co/api/v2/pokemon"
MAX_RETRIES=3
RETRY_DELAY=5
MAX_PARALLEL=3  # Limit concurrent background processes
TIMEOUT_SECONDS=30  # Timeout for each API request

# Function to check if required commands are installed
check_commands() {
    for cmd in curl kill; do
        if ! command -v "$cmd" &> /dev/null; then
            echo "$cmd is not installed. Please install $cmd to proceed." >&2
            exit 1
        fi
    done
}

# Function to create output directory if it doesn't exist
create_output_dir() {
    if [ ! -d "$OUTPUT_DIR" ]; then
        mkdir -p "$OUTPUT_DIR"
        if [ $? -ne 0 ]; then
            echo "$(date '+%Y-%m-%d %H:%M:%S'): Failed to create directory $OUTPUT_DIR" >> "$ERROR_FILE"
            echo "Error: Failed to create directory $OUTPUT_DIR" >&2
            exit 1
        fi
    fi
}

# Function to fetch Pokémon data with retry logic and timeout
fetch_pokemon_data() {
    local pokemon=$1
    local output_file="$OUTPUT_DIR/${pokemon}.json"
    local attempt=1
    local success=0
    local pid

    echo "Fetching data for $pokemon..."

    while [ $attempt -le $MAX_RETRIES ] && [ $success -eq 0 ]; do
        # Run curl in background with timeout
        {
            http_code=$(curl -s -w "%{http_code}" -o "$output_file" "$API_BASE_URL/$pokemon" 2>>"$ERROR_FILE")
            if [ "$http_code" -eq 200 ]; then
                echo "Saved data to $output_file ✅"
                exit 0
            else
                echo "$(date '+%Y-%m-%d %H:%M:%S'): Attempt $attempt failed for $pokemon. HTTP status code: $http_code" >> "$ERROR_FILE"
                exit 1
            fi
        } &
        pid=$!

        # Wait for the process with timeout
        for ((i=0; i<$TIMEOUT_SECONDS; i++)); do
            if ! ps -p $pid > /dev/null; then
                break
            fi
            sleep 1
        done

        # Check if process is still running (timeout exceeded)
        if ps -p $pid > /dev/null; then
            kill $pid 2>/dev/null
            wait $pid 2>/dev/null
            echo "$(date '+%Y-%m-%d %H:%M:%S'): Process for $pokemon (PID $pid) timed out after $TIMEOUT_SECONDS seconds and was killed" >> "$ERROR_FILE"
            echo "Error: Request for $pokemon timed out and was terminated" >&2
        else
            # Check if the last attempt was successful
            wait $pid
            if [ $? -eq 0 ]; then
                success=1
            fi
        fi

        if [ $success -eq 0 ] && [ $attempt -lt $MAX_RETRIES ]; then
            echo "Retrying ($attempt/$MAX_RETRIES) for $pokemon after $RETRY_DELAY seconds..."
            sleep "$RETRY_DELAY"
        elif [ $success -eq 0 ]; then
            echo "Error: Failed to fetch data for $pokemon after $MAX_RETRIES attempts. Check $ERROR_FILE for details." >&2
            rm -f "$output_file"
        fi
        ((attempt++))
    done
}

# Function to manage parallel processes
manage_parallel_fetch() {
    local active_jobs=0
    local pokemon
    local pids=()

    for pokemon in "${POKEMON_LIST[@]}"; do
        # Wait if max parallel jobs reached
        while [ $active_jobs -ge $MAX_PARALLEL ]; do
            wait -n
            ((active_jobs--))
        done

        # Start fetch in background and store PID
        fetch_pokemon_data "$pokemon" &
        pids+=($!)
        ((active_jobs++))
    done

    # Wait for all background processes to complete
    for pid in "${pids[@]}"; do
        wait $pid 2>/dev/null
    done

    # Verify all expected files were created
    for pokemon in "${POKEMON_LIST[@]}"; do
        if [ ! -f "$OUTPUT_DIR/${pokemon}.json" ]; then
            echo "$(date '+%Y-%m-%d %H:%M:%S'): Missing output file for $pokemon" >> "$ERROR_FILE"
            echo "Error: Data for $pokemon was not successfully retrieved" >&2
        fi
    done
}

# Main execution
check_commands

# Create or clear error file
: > "$ERROR_FILE"

# Create output directory
create_output_dir

# Fetch data in parallel
manage_parallel_fetch

# Summary of results
echo "Data retrieval completed. Check $ERROR_FILE for any errors."
exit 0